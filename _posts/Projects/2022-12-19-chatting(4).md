---
title: "실시간 채팅방 구현(4)"
categories:
  - 프로젝트
  - Spring
date: 2022-12-19 13:00:25 +0900
tags:
---
### 추가내용
#### 문제점2. 메모리상에서 유저데이터의 복제 해결 방법
이전 포스팅[[실시간 채팅방 구현(2)]](https://ghkdqhrbals.github.io/posts/chatting(2)/)에서 문제점2인 **메모리상 유저데이터 복제**가 일어난다고 기술했다. 이를 해결하기 위해 sticky session과 같이 kafka 파티셔닝을 진행한다고 하였다. 상세내용은 아래의 코드를 통해 보이겠다.


```java
// 역할1. Kafka 토픽 할당
@Configuration
public class KafkaTopicConfig {

    @Autowired
    private KafkaAdmin kafkaAdmin;

    @Value("${kafka.topic-login}") // app.properties 에서 미리 정의해놓고 가져옴
    public String TOPIC_LOGIN;

    private NewTopic generateTopic(String topicName) {
        return TopicBuilder.name(topicName)
                .partitions(2) // 파티션 할당 개수
                .replicas(2) // broker 2대에 할당
                .build(); // 즉, 토픽은 총 2개의 leader-partition, 2개의 follow-partition 보유
    }

    @PostConstruct
    public void init() {
        kafkaAdmin.createOrModifyTopics(generateTopic(TOPIC_LOGIN));
    }
}
```

```java
@Configuration
@EnableKafka
public class KafkaProducerConfig {

    @Value("${kafka.bootstrap-servers}")
    private String bootstrapServer;

    private ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        // Kafka Broker 엔드 포인트 할당(29092, 39092, 49092)
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);
        // Kafka에 전송될 키는 스트링으로 설정
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        // Kafka에 전송될 값을 직렬화 하는 방법을 지정
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);

        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, Object> kafkaProducerTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

}
```
```java
@Slf4j
@RestController
@RequestMapping("/api")
public class KafkaProducerController {
    // kafka producer를 위한 KafkaTemplate를 지정한다.
    private final KafkaTemplate<String, Object> kafkaProducerTemplate;

    ...

    // 임시로 PostMapping하였다.
    // 역할1. userId와 userPw를 담은 RequestLoginDTO가 도착하면 이를 kafka의 특정 파티션으로 전송
    @PostMapping("login")
    public ResponseEntity<?> produceMessageWithRequestLoginDTO(@RequestBody RequestLoginDTO requestLoginDTO) {

        // 이부분이 중요하다!!!!
        // userId를 Kafka의 토픽에 key로 던져주면서 특정 파티션에 들어가도록 설정한다
        // (던져주면 partition = HASH(useriD) mod (파티션개수) 로 수행할듯)
        ListenableFuture<SendResult<String, Object>> future = kafkaProducerTemplate.send(TOPIC_LOGIN, requestLoginDTO.getUserId(), requestLoginDTO);

        // callback
        future.addCallback(new ListenableFutureCallback<SendResult<String, Object>>() {
            @Override
            public void onFailure(Throwable ex) {
                log.error("Unable to send message: {}", ex.getMessage());
            }

            @Override
            public void onSuccess(SendResult<String, Object> result) {
                log.info("Sent message with key: {}, offset: {}, partition: {}", requestLoginDTO.getUserId(), result.getRecordMetadata().offset(), result.getRecordMetadata().partition());
            }
        });
        return ResponseEntity.ok(requestLoginDTO);
    }
}
```
```java
// 역할1. Kafka연결
// 역할2. 메세지를 받아서 우리가 원하는 타입인 RequestLoginDTO로 변환
@Slf4j
@EnableKafka
@Configuration
public class KafkaConsumerConfig {

    @Value("${kafka.bootstrap-servers}")
    private String bootstrapServer;

    ...

    // login consumer 객체 변환
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, RequestLoginDTO> loginKafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, RequestLoginDTO> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(loginConsumerFactory("chatServerGroup"));
        return factory;
    }

    // login consumer 객체 변환
    public ConsumerFactory<String, RequestLoginDTO> loginConsumerFactory(String groupId) {

        // 앞서 producer이 json직렬화로 보냈으니, 마찬가지로 jsonDeserialize
        JsonDeserializer<RequestLoginDTO> deserializer = new JsonDeserializer<>(RequestLoginDTO.class);
        deserializer.setRemoveTypeHeaders(false);
        // 모든 패키지 신뢰
        deserializer.addTrustedPackages("*");
        deserializer.setUseTypeMapperForKey(true);

        // 객체변환 설정
        ImmutableMap<String, Object> config = ImmutableMap.<String, Object>builder()
                .put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer)
                .put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class)
                .put(ConsumerConfig.GROUP_ID_CONFIG, groupId)
                // 역직렬화 로직
                .put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, deserializer)
                .build();

        return new DefaultKafkaConsumerFactory<>(config, new StringDeserializer(), deserializer);
    }
}
```

```java
@Slf4j
@Component
public class MessageListener {

    ...

    @KafkaListener(topics = "${kafka.topic-login}", containerFactory = "loginKafkaListenerContainerFactory")
    public void listenLogin(RequestLoginDTO loginDTO) {
      log.info("Receive [RequestLoginDTO] Message with userID={},userPw={}",loginDTO.getUserId(),loginDTO.getUserPw());
    }
}
```

유저의 ID는 모든 서비스에 필요한 중요한 key이며 유니크하다. `kafkaProducerTemplate.send(.., key=userId, ..)`로 front에서 kafka의 특정 파티션으로 들어가도록 하고, 해당 파티션은 backend 서버 중 하나가 계속(만약 계속 살아있다면) 읽게된다면 메모리의 중복사용이 해결된다.

> 참고로 Kafka브로커는 3대(port:29092, 39092, 49092)를 설정하였고 docker compose를 통해 실행하였다.


